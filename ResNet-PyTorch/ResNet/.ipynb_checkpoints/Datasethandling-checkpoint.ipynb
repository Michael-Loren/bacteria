{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f917bdb6-118b-4a25-ac24-b150ff6c72d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "NVIDIA GeForce RTX 4070\n",
      "Using device: cuda\n",
      "Using device: cuda\n",
      "Matrix multiplication result: tensor([[2496.9382, 2500.2336, 2523.8225,  ..., 2498.3140, 2504.1028,\n",
      "         2502.7761],\n",
      "        [2468.2634, 2485.7952, 2474.4102,  ..., 2486.7542, 2486.3315,\n",
      "         2487.6743],\n",
      "        [2503.8313, 2506.0791, 2511.8677,  ..., 2508.1436, 2487.8643,\n",
      "         2506.3521],\n",
      "        ...,\n",
      "        [2499.8242, 2504.5310, 2512.2795,  ..., 2496.6399, 2487.8442,\n",
      "         2510.6089],\n",
      "        [2501.0007, 2497.7581, 2499.7617,  ..., 2495.7104, 2508.0000,\n",
      "         2499.3867],\n",
      "        [2483.2737, 2500.0310, 2507.8948,  ..., 2486.5632, 2486.1135,\n",
      "         2502.5884]], device='cuda:0')\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import scipy.io\n",
    "import torch.nn as nn  # Import nn module\n",
    "import torch.optim as optim  # Import optim module\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from hyperspectral_dataset import HyperspectralDataset, compute_statistics, NormalizeCube, NormalizeProfile\n",
    "from rgb_dataset import RGBDataset\n",
    "from torchvision.transforms import Resize, CenterCrop, Compose, Normalize, ToTensor\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from ResNet import CustomResNet50  # Assuming ResNet50 is defined in ResNet.py\n",
    "import torch\n",
    "print(torch.cuda.is_available())  # Should return True\n",
    "print(torch.cuda.get_device_name(0))  # Should print the name of your GPU\n",
    "# Check for CUDA\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# Create a random tensor and move it to the GPU\n",
    "x = torch.rand(10000, 10000).to(device)\n",
    "y = torch.rand(10000, 10000).to(device)\n",
    "\n",
    "# Perform a matrix multiplication on the GPU\n",
    "z = torch.matmul(x, y)\n",
    "\n",
    "print(\"Matrix multiplication result:\", z)\n",
    "print(\"Done.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69c172e4-ee83-47e4-aba8-efca02e99daa",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'normalize' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 12\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m file_paths\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# # Initialize the dataset with transformations\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# dataset = RGBDataset(root_dir='../../../serverstuff/hsi/all')\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# channel_means_cube, channel_stds_cube, channel_means_profile, channel_stds_profile = compute_statistics(dataset)\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m transform \u001b[38;5;241m=\u001b[39m transforms\u001b[38;5;241m.\u001b[39mCompose([Resize((\u001b[38;5;241m256\u001b[39m, \u001b[38;5;241m256\u001b[39m)), CenterCrop((\u001b[38;5;241m256\u001b[39m, \u001b[38;5;241m256\u001b[39m)), ToTensor(), \u001b[43mnormalize\u001b[49m])\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Apply the custom transforms to the datasets\u001b[39;00m\n\u001b[1;32m     15\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m RGBDataset(root_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../../../serverstuff/hsi/train\u001b[39m\u001b[38;5;124m'\u001b[39m, transform\u001b[38;5;241m=\u001b[39mtransform)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'normalize' is not defined"
     ]
    }
   ],
   "source": [
    "# Function to get all file paths from a dataset\n",
    "def get_all_file_paths(dataset):\n",
    "    file_paths = []\n",
    "    # for idx in range(len(dataset)):\n",
    "    file_paths.append(dataset.get_image_path(idx))\n",
    "    return file_paths\n",
    "\n",
    "# # Initialize the dataset with transformations\n",
    "# dataset = RGBDataset(root_dir='../../../serverstuff/hsi/all')\n",
    "# channel_means_cube, channel_stds_cube, channel_means_profile, channel_stds_profile = compute_statistics(dataset)\n",
    "\n",
    "normalize = Normalize(mean=feature_extractor.image_mean, std=feature_extractor.image_std)\n",
    "transform = transforms.Compose([Resize((256, 256)), CenterCrop((256, 256)), ToTensor(), normalize])\n",
    "\n",
    "# Apply the custom transforms to the datasets\n",
    "train_dataset = RGBDataset(root_dir='../../../serverstuff/hsi/train', transform=transform)\n",
    "val_dataset = RGBDataset(root_dir='../../../serverstuff/hsi/validation', transform=transform)\n",
    "test_dataset = RGBDataset(root_dir='../../../serverstuff/hsi/test', transform=transform)\n",
    "\n",
    "# Create DataLoaders for training, validation, and test sets\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ccab103-2289-4111-bf41-0447ae956224",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Function to get all file paths from a dataset\n",
    "# def get_all_file_paths(dataset):\n",
    "#     file_paths = []\n",
    "#     for idx in range(len(dataset)):\n",
    "#         file_paths.append(dataset.get_image_path(idx))\n",
    "#     return file_paths\n",
    "\n",
    "# # # Initialize the dataset with transformations\n",
    "# dataset = HyperspectralDataset(root_dir='../../dibasRP/all')\n",
    "# # channel_means_cube, channel_stds_cube, channel_means_profile, channel_stds_profile = compute_statistics(dataset)\n",
    "\n",
    "# channel_means_cube, channel_stds_cube, channel_means_profile, channel_stds_profile = [0.5] * 31, [0.5] * 31, [0.5] * 31, [0.5] * 31\n",
    "# # Define the custom transformations using the computed statistics\n",
    "# cube_transform = NormalizeCube(mean=channel_means_cube, std=channel_stds_cube)\n",
    "# profile_transform = NormalizeProfile(mean=channel_means_profile, std=channel_stds_profile)\n",
    "\n",
    "# # Apply the custom transforms to the datasets\n",
    "# train_dataset = HyperspectralDataset(root_dir='../../dibasRP/train', cube_transform=cube_transform)\n",
    "# val_dataset = HyperspectralDataset(root_dir='../../dibasRP/val', cube_transform=cube_transform)\n",
    "# test_dataset = HyperspectralDataset(root_dir='../../dibasRP/test', cube_transform=cube_transform)\n",
    "\n",
    "# # Create DataLoaders for training, validation, and test sets\n",
    "# train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=4)\n",
    "# val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False, num_workers=4)\n",
    "# test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4795d9f6-ad04-426c-82c3-64aeab302962",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get file paths for the main dataset and each split\n",
    "# main_dataset_paths = get_all_file_paths(dataset)\n",
    "# train_dataset_paths = get_all_file_paths(train_dataset)\n",
    "# val_dataset_paths = get_all_file_paths(val_dataset)\n",
    "# test_dataset_paths = get_all_file_paths(test_dataset)\n",
    "\n",
    "# # Check if the total length of the splits equals the length of the main dataset\n",
    "# total_split_length = len(train_dataset_paths) + len(val_dataset_paths) + len(test_dataset_paths)\n",
    "# if total_split_length != len(main_dataset_paths):\n",
    "#     print(f\"Error: Total length of splits ({total_split_length}) does not equal length of main dataset ({len(main_dataset_paths)})\")\n",
    "# else:\n",
    "#     print(\"Total length of splits matches the length of the main dataset.\")\n",
    "\n",
    "# # Check for overlaps between splits\n",
    "# def check_for_overlaps(paths1, paths2):\n",
    "#     overlaps = set(paths1) & set(paths2)\n",
    "#     return overlaps\n",
    "\n",
    "# train_val_overlaps = check_for_overlaps(train_dataset_paths, val_dataset_paths)\n",
    "# train_test_overlaps = check_for_overlaps(train_dataset_paths, test_dataset_paths)\n",
    "# val_test_overlaps = check_for_overlaps(val_dataset_paths, test_dataset_paths)\n",
    "\n",
    "# if train_val_overlaps:\n",
    "#     print(f\"Error: Overlaps found between train and validation datasets: {len(train_val_overlaps)} overlaps\")\n",
    "# else:\n",
    "#     print(\"No overlaps found between train and validation datasets.\")\n",
    "\n",
    "# if train_test_overlaps:\n",
    "#     print(f\"Error: Overlaps found between train and test datasets: {len(train_test_overlaps)} overlaps\")\n",
    "# else:\n",
    "#     print(\"No overlaps found between train and test datasets.\")\n",
    "\n",
    "# if val_test_overlaps:\n",
    "#     print(f\"Error: Overlaps found between validation and test datasets: {len(val_test_overlaps)} overlaps\")\n",
    "# else:\n",
    "#     print(\"No overlaps found between validation and test datasets.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1ffc9f-5658-4b20-9b3d-97ac24c066dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7848eefb-c25f-47f8-8344-d7f9c30ff2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the modified ResNet model\n",
    "from transformers import AutoImageProcessor, AutoModelForImageClassification\n",
    "\n",
    "processor = AutoImageProcessor.from_pretrained(\"facebook/convnextv2-base-1k-224\")\n",
    "model = AutoModelForImageClassification.from_pretrained(\"facebook/convnextv2-base-1k-224\").to(device)\n",
    "\n",
    "# model = CustomResNet50(num_classes=len(train_dataset.label_map)).to(device)\n",
    "# model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1).to(device)\n",
    "for name, param in model.named_parameters():\n",
    "    param.requires_grad = \"classifier\" in name\n",
    "\n",
    "# Get the number of input features of the current classifier layer\n",
    "num_features = model.classifier.in_features\n",
    "\n",
    "# Replace the classifier layer with a new one\n",
    "model.classifier = nn.Linear(num_features, 34).to(device)  # Assuming 10 classes\n",
    "\n",
    "print(model.classifier.out_features)\n",
    "    \n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"{name}: {'requires_grad' if param.requires_grad else 'frozen'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f350094-d65d-4d20-9550-32cce9d0c2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=0.0005)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor = 0.5, patience=5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34fc8890-bf14-4061-8099-b5b8e9c5b194",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "# Initialize lists to store losses, accuracy, and learning rate change epochs\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "train_precisions = []\n",
    "train_recalls = []\n",
    "train_f1_scores = []\n",
    "val_precisions = []\n",
    "val_recalls = []\n",
    "val_f1_scores = []\n",
    "lr_change_epochs = []\n",
    "\n",
    "# Training and validation loop\n",
    "num_epochs = 125  # Set the number of epochs\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_start_time = time.time()  # Start timing the epoch\n",
    "\n",
    "    model.train()  # Set the model to training mode\n",
    "    running_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    all_train_labels = []\n",
    "    all_train_preds = []\n",
    "\n",
    "    for batch_idx, (cubes, labels) in enumerate(train_loader):\n",
    "        cubes, labels = cubes.to(device), labels.to(device)  # Move data to GPU\n",
    "        optimizer.zero_grad()  # Zero the parameter gradients\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(cubes)\n",
    "        loss = criterion(outputs.logits, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # Calculate training accuracy\n",
    "        _, predicted = torch.max(outputs.logits, 1)\n",
    "        total_train += labels.size(0)\n",
    "        correct_train += (predicted == labels).sum().item()\n",
    "\n",
    "        # Store labels and predictions for precision, recall, f1\n",
    "        all_train_labels.extend(labels.cpu().numpy())\n",
    "        all_train_preds.extend(predicted.cpu().numpy())\n",
    "\n",
    "    avg_train_loss = running_loss / len(train_loader)\n",
    "    train_losses.append(avg_train_loss)\n",
    "    train_accuracy = 100 * correct_train / total_train\n",
    "    train_accuracies.append(train_accuracy)\n",
    "\n",
    "    # Calculate precision, recall, f1 score for training\n",
    "    train_precision, train_recall, train_f1, _ = precision_recall_fscore_support(all_train_labels, all_train_preds, average='weighted')\n",
    "    train_precisions.append(train_precision)\n",
    "    train_recalls.append(train_recall)\n",
    "    train_f1_scores.append(train_f1)\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_train_loss:.4f}, Training Accuracy: {train_accuracy:.2f}%, Precision: {train_precision:.3f}, Recall: {train_recall:.3f}, F1 Score: {train_f1:.3f}\")\n",
    "\n",
    "    # Validation loop\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    val_loss = 0.0\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "    all_val_labels = []\n",
    "    all_val_preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for cubes, labels in val_loader:\n",
    "            cubes, labels = cubes.to(device), labels.to(device)  # Move data to GPU\n",
    "            outputs = model(cubes)\n",
    "            loss = criterion(outputs.logits, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs.logits, 1)\n",
    "            total_val += labels.size(0)\n",
    "            correct_val += (predicted == labels).sum().item()\n",
    "\n",
    "            # Store labels and predictions for precision, recall, f1\n",
    "            all_val_labels.extend(labels.cpu().numpy())\n",
    "            all_val_preds.extend(predicted.cpu().numpy())\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    val_losses.append(avg_val_loss)\n",
    "    val_accuracy = 100 * correct_val / total_val\n",
    "    val_accuracies.append(val_accuracy)\n",
    "\n",
    "    # Calculate precision, recall, f1 score for validation\n",
    "    val_precision, val_recall, val_f1, _ = precision_recall_fscore_support(all_val_labels, all_val_preds, average='weighted')\n",
    "    val_precisions.append(val_precision)\n",
    "    val_recalls.append(val_recall)\n",
    "    val_f1_scores.append(val_f1)\n",
    "\n",
    "    print(f\"Validation Loss: {avg_val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%, Precision: {val_precision:.3f}, Recall: {val_recall:.3f}, F1 Score: {val_f1:.3f}\")\n",
    "\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    scheduler.step(avg_val_loss)\n",
    "    new_lr = optimizer.param_groups[0]['lr']\n",
    "    if new_lr < current_lr:\n",
    "        print(f\"Learning rate reduced from {current_lr} to {new_lr}\")\n",
    "        lr_change_epochs.append(epoch+1)  # Log the epoch where the learning rate changed\n",
    "\n",
    "    epoch_end_time = time.time()  # End timing the epoch\n",
    "    epoch_duration = epoch_end_time - epoch_start_time\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}] completed in {epoch_duration:.2f} seconds\")\n",
    "\n",
    "print(\"Training complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a940e7b1-0479-4aaa-ba22-9bcddc094ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training and validation losses with learning rate change points\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "for lr_epoch in lr_change_epochs:\n",
    "    plt.axvline(x=lr_epoch, color='r', linestyle='--', label='LR Change' if lr_epoch == lr_change_epochs[0] else \"\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('Training and Validation Losses with Learning Rate Changes')\n",
    "plt.grid(True)  # Add gridlines\n",
    "plt.show()\n",
    "\n",
    "# Plot the training and validation accuracy\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_accuracies, label='Training Accuracy')\n",
    "plt.plot(val_accuracies, label='Validation Accuracy')\n",
    "for lr_epoch in lr_change_epochs:\n",
    "    plt.axvline(x=lr_epoch, color='r', linestyle='--', label='LR Change' if lr_epoch == lr_change_epochs[0] else \"\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.grid(True)  # Add gridlines\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbcfaec-3c92-48ec-8db6-db238994a7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing loop\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "test_loss = 0.0\n",
    "correct = 0\n",
    "total = 0 \n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)  # Move data to GPU\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs.logits, labels)\n",
    "        test_loss += loss.item()\n",
    "\n",
    "        _, predicted = torch.max(outputs.logits, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"Test Loss: {test_loss/len(test_loader):.4f}, Test Accuracy: {accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2713b96c-07e1-4684-8be7-32d7237d330e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Function to test an individual sample and collect predictions and true labels\n",
    "def test_individual_test_sample(sample_idx, true_labels, predicted_labels):\n",
    "    # Load a specific sample from the test dataset\n",
    "    cube, label = test_dataset[sample_idx]\n",
    "    \n",
    "    # Move the sample to GPU if using CUDA\n",
    "    cube = cube.to(device).unsqueeze(0)  # Add batch dimension\n",
    "    label = label.to(device)\n",
    "    \n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Disable gradient computation for inference\n",
    "    with torch.no_grad():\n",
    "        output = model(cube)\n",
    "    \n",
    "    # Apply softmax to get probabilities\n",
    "    probabilities = torch.nn.functional.softmax(output.logits, dim=1)\n",
    "    \n",
    "    # Get the predicted class\n",
    "    predicted_class = torch.argmax(probabilities, dim=1)\n",
    "    \n",
    "    # Append the true and predicted labels to their respective lists\n",
    "    true_labels.append(label.item())\n",
    "    predicted_labels.append(predicted_class.item())\n",
    "\n",
    "# Lists to store true and predicted labels\n",
    "true_labels = []\n",
    "predicted_labels = []\n",
    "\n",
    "# Test individual samples and collect labels\n",
    "for i in range(len(test_dataset)):\n",
    "    test_individual_test_sample(i, true_labels, predicted_labels)\n",
    "\n",
    "# Convert lists to numpy arrays for compatibility with sklearn\n",
    "true_labels = np.array(true_labels)\n",
    "predicted_labels = np.array(predicted_labels)\n",
    "\n",
    "# Generate the confusion matrix\n",
    "cm = confusion_matrix(true_labels, predicted_labels)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(10, 10))\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9776e3-04f4-4284-92a5-1a3c21285ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'resnet.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f680598d-3493-465e-a178-c6671d8789f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa40e29-9da0-4aae-8643-4ff7f62eebde",
   "metadata": {},
   "outputs": [],
   "source": [
    "models.save("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f4bd7c-c533-4da8-ae2e-01e0592b688d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for a, b in enumerate(train_loader):\n",
    "    print(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288302df-d519-4dd6-8a39-d5395562fd89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venvres)",
   "language": "python",
   "name": "venvres"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
