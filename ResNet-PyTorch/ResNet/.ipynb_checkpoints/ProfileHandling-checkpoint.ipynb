{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7335927-4429-475a-9468-da1c97ca05eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import scipy.io\n",
    "import torch.nn as nn  # Import nn module\n",
    "import torch.optim as optim  # Import optim module\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from hyperspectral_dataset import HyperspectralDataset, CustomTransform\n",
    "\n",
    "from pnet import pNet\n",
    "\n",
    "# Check for CUDA\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7558f2c1-8172-4dde-800f-b85f7c4655d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dcf57ec9-cbf9-4700-b30e-3409896d5dca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label mapping: {'Acinetobacter_baumanii': 0, 'Lactobacillus_casei': 1, 'Lactobacillus_jehnsenii': 2, 'Lactobacillus_gasseri': 3, 'Lactobacillus_delbrueckii': 4, 'Lactobacillus_salivarius': 5, 'Propionibacterium_acnes': 6, 'Lactobacillus_paracasei': 7, 'Bifidobacterium_spp': 8, 'Lactobacillus_reuteri': 9, 'Staphylococcus_aureus': 10, 'Escherichia_coli': 11, 'Lactobacillus_rhamnosus': 12, 'Lactobacillus_plantarum': 13, 'Enterococcus_faecium': 14, 'Porfyromonas_gingivalis': 15, 'Enterococcus_faecalis': 16, 'Micrococcus_spp': 17, 'Fusobacterium': 18, 'Actinomyces_israeli': 19, 'Lactobacillus_crispatus': 20, 'Clostridium_perfringens': 21, 'Staphylococcus_epidermidis': 22, 'Listeria_monocytogenes': 23, 'Pseudomonas_aeruginosa': 24, 'Lactobacillus_johnsonii': 25, 'Streptococcus_agalactiae': 26, 'Staphylococcus_saprophiticus': 27, 'Bacteroides_fragilis': 28, 'Neisseria_gonorrhoeae': 29, 'Veionella': 30, 'Proteus': 31, 'Candida_albicans': 32}\n",
      "Label mapping: {'Acinetobacter_baumanii': 0, 'Lactobacillus_casei': 1, 'Lactobacillus_jehnsenii': 2, 'Lactobacillus_gasseri': 3, 'Lactobacillus_delbrueckii': 4, 'Lactobacillus_salivarius': 5, 'Propionibacterium_acnes': 6, 'Lactobacillus_paracasei': 7, 'Bifidobacterium_spp': 8, 'Lactobacillus_reuteri': 9, 'Staphylococcus_aureus': 10, 'Escherichia_coli': 11, 'Lactobacillus_rhamnosus': 12, 'Lactobacillus_plantarum': 13, 'Enterococcus_faecium': 14, 'Porfyromonas_gingivalis': 15, 'Enterococcus_faecalis': 16, 'Micrococcus_spp': 17, 'Fusobacterium': 18, 'Actinomyces_israeli': 19, 'Lactobacillus_crispatus': 20, 'Clostridium_perfringens': 21, 'Staphylococcus_epidermidis': 22, 'Listeria_monocytogenes': 23, 'Pseudomonas_aeruginosa': 24, 'Lactobacillus_johnsonii': 25, 'Streptococcus_agalactiae': 26, 'Staphylococcus_saprophiticus': 27, 'Bacteroides_fragilis': 28, 'Neisseria_gonorrhoeae': 29, 'Veionella': 30, 'Proteus': 31, 'Candida_albicans': 32}\n",
      "Label mapping: {'Acinetobacter_baumanii': 0, 'Lactobacillus_casei': 1, 'Lactobacillus_jehnsenii': 2, 'Lactobacillus_gasseri': 3, 'Lactobacillus_delbrueckii': 4, 'Lactobacillus_salivarius': 5, 'Propionibacterium_acnes': 6, 'Lactobacillus_paracasei': 7, 'Bifidobacterium_spp': 8, 'Lactobacillus_reuteri': 9, 'Staphylococcus_aureus': 10, 'Escherichia_coli': 11, 'Lactobacillus_rhamnosus': 12, 'Lactobacillus_plantarum': 13, 'Enterococcus_faecium': 14, 'Porfyromonas_gingivalis': 15, 'Enterococcus_faecalis': 16, 'Micrococcus_spp': 17, 'Fusobacterium': 18, 'Actinomyces_israeli': 19, 'Lactobacillus_crispatus': 20, 'Clostridium_perfringens': 21, 'Staphylococcus_epidermidis': 22, 'Listeria_monocytogenes': 23, 'Pseudomonas_aeruginosa': 24, 'Lactobacillus_johnsonii': 25, 'Streptococcus_agalactiae': 26, 'Staphylococcus_saprophiticus': 27, 'Bacteroides_fragilis': 28, 'Neisseria_gonorrhoeae': 29, 'Veionella': 30, 'Proteus': 31, 'Candida_albicans': 32}\n",
      "Label mapping: {'Acinetobacter_baumanii': 0, 'Lactobacillus_casei': 1, 'Lactobacillus_jehnsenii': 2, 'Lactobacillus_gasseri': 3, 'Lactobacillus_delbrueckii': 4, 'Lactobacillus_salivarius': 5, 'Propionibacterium_acnes': 6, 'Lactobacillus_paracasei': 7, 'Bifidobacterium_spp': 8, 'Lactobacillus_reuteri': 9, 'Staphylococcus_aureus': 10, 'Escherichia_coli': 11, 'Lactobacillus_rhamnosus': 12, 'Lactobacillus_plantarum': 13, 'Enterococcus_faecium': 14, 'Porfyromonas_gingivalis': 15, 'Enterococcus_faecalis': 16, 'Micrococcus_spp': 17, 'Fusobacterium': 18, 'Actinomyces_israeli': 19, 'Lactobacillus_crispatus': 20, 'Clostridium_perfringens': 21, 'Staphylococcus_epidermidis': 22, 'Listeria_monocytogenes': 23, 'Pseudomonas_aeruginosa': 24, 'Lactobacillus_johnsonii': 25, 'Streptococcus_agalactiae': 26, 'Staphylococcus_saprophiticus': 27, 'Bacteroides_fragilis': 28, 'Neisseria_gonorrhoeae': 29, 'Veionella': 30, 'Proteus': 31, 'Candida_albicans': 32}\n",
      "Cube shape: torch.Size([4, 31, 224, 224]), Profile shape: torch.Size([4, 1, 31]), Label: tensor([12, 27, 21, 28])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Function to get all file paths from a dataset\n",
    "def get_all_file_paths(dataset):\n",
    "    file_paths = []\n",
    "    for idx in range(len(dataset)):\n",
    "        file_paths.append(dataset.get_image_path(idx))\n",
    "    return file_paths\n",
    "\n",
    "# Initialize the dataset with transformations\n",
    "dataset = HyperspectralDataset(root_dir='../../dibasRP/all')\n",
    "\n",
    "# Define mean and std for cube and profile (replace these with actual values if available)\n",
    "channel_means_cube = [0.5] * 31\n",
    "channel_stds_cube = [0.5] * 31\n",
    "channel_means_profile = [0.5] * 31\n",
    "channel_stds_profile = [0.5] * 31\n",
    "\n",
    "# Define the custom transformation including normalization and resizing\n",
    "custom_transform = CustomTransform(\n",
    "    cube_mean=channel_means_cube, \n",
    "    cube_std=channel_stds_cube, \n",
    "    profile_mean=channel_means_profile, \n",
    "    profile_std=channel_stds_profile,\n",
    "    resize_shape=(224, 224)  # Resize cube to 224x224\n",
    ")\n",
    "\n",
    "# Apply the custom transforms to the datasets\n",
    "train_dataset = HyperspectralDataset(root_dir='../../dibasRP/train', transform=custom_transform)\n",
    "val_dataset = HyperspectralDataset(root_dir='../../dibasRP/val', transform=custom_transform)\n",
    "test_dataset = HyperspectralDataset(root_dir='../../dibasRP/test', transform=custom_transform)\n",
    "\n",
    "# Create DataLoaders for training, validation, and test sets\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False, num_workers=4)\n",
    "\n",
    "# Example to verify the changes\n",
    "for sample, label in train_loader:\n",
    "    print(f\"Cube shape: {sample['cube'].shape}, Profile shape: {sample['profile'].shape}, Label: {label}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45960364-cec4-40cc-8f65-a48b75164c04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total length of splits matches the length of the main dataset.\n",
      "No overlaps found between train and validation datasets.\n",
      "No overlaps found between train and test datasets.\n",
      "No overlaps found between validation and test datasets.\n"
     ]
    }
   ],
   "source": [
    "# Get file paths for the main dataset and each split\n",
    "main_dataset_paths = get_all_file_paths(dataset)\n",
    "train_dataset_paths = get_all_file_paths(train_dataset)\n",
    "val_dataset_paths = get_all_file_paths(val_dataset)\n",
    "test_dataset_paths = get_all_file_paths(test_dataset)\n",
    "\n",
    "# Check if the total length of the splits equals the length of the main dataset\n",
    "total_split_length = len(train_dataset_paths) + len(val_dataset_paths) + len(test_dataset_paths)\n",
    "if total_split_length != len(main_dataset_paths):\n",
    "    print(f\"Error: Total length of splits ({total_split_length}) does not equal length of main dataset ({len(main_dataset_paths)})\")\n",
    "else:\n",
    "    print(\"Total length of splits matches the length of the main dataset.\")\n",
    "\n",
    "# Check for overlaps between splits\n",
    "def check_for_overlaps(paths1, paths2):\n",
    "    overlaps = set(paths1) & set(paths2)\n",
    "    return overlaps\n",
    "\n",
    "train_val_overlaps = check_for_overlaps(train_dataset_paths, val_dataset_paths)\n",
    "train_test_overlaps = check_for_overlaps(train_dataset_paths, test_dataset_paths)\n",
    "val_test_overlaps = check_for_overlaps(val_dataset_paths, test_dataset_paths)\n",
    "\n",
    "if train_val_overlaps:\n",
    "    print(f\"Error: Overlaps found between train and validation datasets: {len(train_val_overlaps)} overlaps\")\n",
    "else:\n",
    "    print(\"No overlaps found between train and validation datasets.\")\n",
    "\n",
    "if train_test_overlaps:\n",
    "    print(f\"Error: Overlaps found between train and test datasets: {len(train_test_overlaps)} overlaps\")\n",
    "else:\n",
    "    print(\"No overlaps found between train and test datasets.\")\n",
    "\n",
    "if val_test_overlaps:\n",
    "    print(f\"Error: Overlaps found between validation and test datasets: {len(val_test_overlaps)} overlaps\")\n",
    "else:\n",
    "    print(\"No overlaps found between validation and test datasets.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0a4f716-a0bd-4fcd-aba8-3a7922205819",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pNet().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42165c1f-0528-48a9-bd29-9da301f262e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=0.0005)\n",
    "\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.5, patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fbd4b2-8dc6-4e78-a492-dc65f0c709b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3269e6d1-ee1b-4892-86fe-049368fd6234",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5274fc43-539b-485c-92c7-6de57834d406",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aaefa8d5-6814-407d-a7ac-9a45018bf278",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'logits'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 36\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[1;32m     35\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(profiles)\n\u001b[0;32m---> 36\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(\u001b[43moutputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogits\u001b[49m, labels)\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# Backward pass and optimization\u001b[39;00m\n\u001b[1;32m     39\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'logits'"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "# Initialize lists to store losses, accuracy, and learning rate change epochs\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "train_precisions = []\n",
    "train_recalls = []\n",
    "train_f1_scores = []\n",
    "val_precisions = []\n",
    "val_recalls = []\n",
    "val_f1_scores = []\n",
    "lr_change_epochs = []\n",
    "\n",
    "# Training and validation loop\n",
    "num_epochs = 125  # Set the number of epochs\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_start_time = time.time()  # Start timing the epoch\n",
    "\n",
    "    model.train()  # Set the model to training mode\n",
    "    running_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    all_train_labels = []\n",
    "    all_train_preds = []\n",
    "\n",
    "    for batch_idx, (sample, labels) in enumerate(train_loader):\n",
    "        profiles = sample['profile']  # Extract profile from the dictionary\n",
    "        profiles, labels = profiles.to(device), labels.to(device)  # Move data to GPU\n",
    "        optimizer.zero_grad()  # Zero the parameter gradients\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(profiles)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # Calculate training accuracy\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total_train += labels.size(0)\n",
    "        correct_train += (predicted == labels).sum().item()\n",
    "\n",
    "        # Store labels and predictions for precision, recall, f1\n",
    "        all_train_labels.extend(labels.cpu().numpy())\n",
    "        all_train_preds.extend(predicted.cpu().numpy())\n",
    "\n",
    "    avg_train_loss = running_loss / len(train_loader)\n",
    "    train_losses.append(avg_train_loss)\n",
    "    train_accuracy = 100 * correct_train / total_train\n",
    "    train_accuracies.append(train_accuracy)\n",
    "\n",
    "    # Calculate precision, recall, f1 score for training\n",
    "    train_precision, train_recall, train_f1, _ = precision_recall_fscore_support(all_train_labels, all_train_preds, average='weighted')\n",
    "    train_precisions.append(train_precision)\n",
    "    train_recalls.append(train_recall)\n",
    "    train_f1_scores.append(train_f1)\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_train_loss:.4f}, Training Accuracy: {train_accuracy:.2f}%, Precision: {train_precision:.3f}, Recall: {train_recall:.3f}, F1 Score: {train_f1:.3f}\")\n",
    "\n",
    "    # Validation loop\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    val_loss = 0.0\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "    all_val_labels = []\n",
    "    all_val_preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for sample, labels in val_loader:\n",
    "            profiles = sample['profile']  # Extract profile from the dictionary\n",
    "            profiles, labels = profiles.to(device), labels.to(device)  # Move data to GPU\n",
    "            outputs = model(profiles)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total_val += labels.size(0)\n",
    "            correct_val += (predicted == labels).sum().item()\n",
    "\n",
    "            # Store labels and predictions for precision, recall, f1\n",
    "            all_val_labels.extend(labels.cpu().numpy())\n",
    "            all_val_preds.extend(predicted.cpu().numpy())\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    val_losses.append(avg_val_loss)\n",
    "    val_accuracy = 100 * correct_val / total_val\n",
    "    val_accuracies.append(val_accuracy)\n",
    "\n",
    "    # Calculate precision, recall, f1 score for validation\n",
    "    val_precision, val_recall, val_f1, _ = precision_recall_fscore_support(all_val_labels, all_val_preds, average='weighted')\n",
    "    val_precisions.append(val_precision)\n",
    "    val_recalls.append(val_recall)\n",
    "    val_f1_scores.append(val_f1)\n",
    "\n",
    "    print(f\"Validation Loss: {avg_val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%, Precision: {val_precision:.3f}, Recall: {val_recall:.3f}, F1 Score: {val_f1:.3f}\")\n",
    "\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    scheduler.step(avg_val_loss)\n",
    "    new_lr = optimizer.param_groups[0]['lr']\n",
    "    if new_lr < current_lr:\n",
    "        print(f\"Learning rate reduced from {current_lr} to {new_lr}\")\n",
    "        lr_change_epochs.append(epoch+1)  # Log the epoch where the learning rate changed\n",
    "\n",
    "    epoch_end_time = time.time()  # End timing the epoch\n",
    "    epoch_duration = epoch_end_time - epoch_start_time\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}] completed in {epoch_duration:.2f} seconds\")\n",
    "\n",
    "print(\"Training complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a95f68-bb8d-4dec-b9fd-a5c88cac9b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training and validation losses with learning rate change points\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "for lr_epoch in lr_change_epochs:\n",
    "    plt.axvline(x=lr_epoch, color='r', linestyle='--', label='LR Change' if lr_epoch == lr_change_epochs[0] else \"\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('Training and Validation Losses with Learning Rate Changes')\n",
    "plt.grid(True)  # Add gridlines\n",
    "plt.show()\n",
    "\n",
    "# Plot the training and validation accuracy\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_accuracies, label='Training Accuracy')\n",
    "plt.plot(val_accuracies, label='Validation Accuracy')\n",
    "for lr_epoch in lr_change_epochs:\n",
    "    plt.axvline(x=lr_epoch, color='r', linestyle='--', label='LR Change' if lr_epoch == lr_change_epochs[0] else \"\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.grid(True)  # Add gridlines\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7b33bc-32a6-4197-bd2d-c4fa68a5275f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Function to test an individual sample and collect predictions and true labels\n",
    "def test_individual_test_sample(sample_idx, true_labels, predicted_labels):\n",
    "    # Load a specific sample from the test dataset\n",
    "    _, profile, label = test_dataset[sample_idx]\n",
    "    \n",
    "    # Move the sample to GPU if using CUDA\n",
    "    profile = profile.to(device).unsqueeze(0)  # Add batch dimension\n",
    "    label = label.to(device)\n",
    "    \n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Disable gradient computation for inference\n",
    "    with torch.no_grad():\n",
    "        output = model(profile)\n",
    "    \n",
    "    # Apply softmax to get probabilities\n",
    "    probabilities = torch.nn.functional.softmax(output, dim=1)\n",
    "    \n",
    "    # Get the predicted class\n",
    "    predicted_class = torch.argmax(probabilities, dim=1)\n",
    "    \n",
    "    # Append the true and predicted labels to their respective lists\n",
    "    true_labels.append(label.item())\n",
    "    predicted_labels.append(predicted_class.item())\n",
    "\n",
    "# Lists to store true and predicted labels\n",
    "true_labels = []\n",
    "predicted_labels = []\n",
    "\n",
    "# Test individual samples and collect labels\n",
    "for i in range(len(test_dataset)):\n",
    "    test_individual_test_sample(i, true_labels, predicted_labels)\n",
    "\n",
    "# Convert lists to numpy arrays for compatibility with sklearn\n",
    "true_labels = np.array(true_labels)\n",
    "predicted_labels = np.array(predicted_labels)\n",
    "\n",
    "# Generate the confusion matrix\n",
    "cm = confusion_matrix(true_labels, predicted_labels)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(10, 10))\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a719c4-8ae8-4107-be5c-455e22b66ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'pnet.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dadecaf-6340-4cfe-8f36-6cd2f80c831d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d42105-a868-45bb-aca3-90fb87ec2379",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venvres)",
   "language": "python",
   "name": "venvres"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
